{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Flatten\n",
    "# from keras.models import Model\n",
    "# from keras.callbacks import EarlyStopping\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, BatchNormalization, Flatten, Dense, Input, Conv1D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "num_sensors = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G8Classifier:\n",
    "    def __init__(self, input_data=None, input_labels=None, input_dims=None, epochs=300, batch_size=16):\n",
    "        # Data\n",
    "        self.input_data = input_data\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "        self.input_labels = input_labels\n",
    "#         self.f_labels = np.zeros(shape=(len(self.input_data), 1, 17))\n",
    "        self.train_labels = None\n",
    "        self.test_labels = None\n",
    "\n",
    "        # Dimensions\n",
    "        self.input_dims = input_dims\n",
    "\n",
    "        # Models\n",
    "        self.decoder_model = None\n",
    "        self.encoder_model = None\n",
    "        self.net_model = None\n",
    "        self.model = None\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=self.input_dims)\n",
    "\n",
    "        x = Conv2D(filters=1024, kernel_size=3,\n",
    "                   padding='same', activation='relu')(inputs)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = MaxPooling2D((2,2), padding='same')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Conv2D(filters=512, kernel_size=3,\n",
    "                   padding='same', activation='relu')(x)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        x = MaxPooling2D((2,2),padding='same')(x)\n",
    "        x = Dropout(0.6)(x)\n",
    "        x = Flatten(input_shape=self.input_dims)(x)\n",
    "        x = Dense(128, activation='relu', activity_regularizer=keras.regularizers.l1(0.00005))(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "        x = Dense(4, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs, x)\n",
    "        print(model.summary())\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"Fitting...\")\n",
    "        self.train_data, self.test_data, self.train_labels, self.test_labels = train_test_split(self.input_data,\n",
    "                                                                                                self.input_labels,\n",
    "                                                                                                test_size=0.2,\n",
    "                                                                                                shuffle=True)\n",
    "        self.train_data = np.reshape(self.train_data, (len(self.train_data), 1, 2, 1000))\n",
    "        print(\"Train Data Shape:\", self.train_data.shape)\n",
    "        self.train_labels = np.reshape(self.train_labels, (len(self.train_labels)))\n",
    "        print(\"Train Labels Shape:\", self.train_labels.shape)\n",
    "\n",
    "        self.test_data = np.reshape(self.test_data, (len(self.test_data), 1, 2, 1000))\n",
    "        self.test_labels = np.reshape(self.test_labels, (len(self.test_labels)))\n",
    "\n",
    "        self.model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "        e_stop = EarlyStopping(monitor='val_loss', patience=50)\n",
    "        self.model.fit(self.train_data, self.train_labels,\n",
    "                       epochs=self.epochs,\n",
    "                       batch_size=self.batch_size,\n",
    "                       validation_data=(self.test_data, self.test_labels),\n",
    "                       callbacks=[e_stop])\n",
    "        print(\"Model fitting complete\")\n",
    "\n",
    "        test_loss, test_acc = self.model.evaluate(self.test_data, self.test_labels)\n",
    "        print('Test accuracy:', test_acc)\n",
    "\n",
    "        predictions = self.model.predict(self.test_data)\n",
    "#         np.savetxt(\"Error.txt\", (predictions-self.test_labels))\n",
    "#         print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (430, 2, 1000)\n"
     ]
    }
   ],
   "source": [
    "wrist_none_data_raw = np.concatenate((np.genfromtxt ('../EMG_data/ife_wrist_none.csv', delimiter=\",\"), np.genfromtxt ('../EMG_data/ife_wrist_none_0.csv', delimiter=\",\")), axis=0 )\n",
    "\n",
    "wrist_none_data = np.zeros( (2, int(wrist_none_data_raw.shape[0]/2), 1000 ) )\n",
    "\n",
    "for i in range(0, wrist_none_data_raw.shape[0]):\n",
    "    wrist_none_data[i%2][int((i-i%2)/2)] = wrist_none_data_raw[i][0:1000]\n",
    "\n",
    "wrist_none_data = wrist_none_data.reshape(wrist_none_data.shape[1],wrist_none_data.shape[0], 1000)\n",
    "# print(wrist_none_data.shape)\n",
    "# ---------------------------------------------------------------------------------#\n",
    "clench_data_raw = np.concatenate((np.genfromtxt ('../EMG_data/ife_clench.csv', delimiter=\",\"),np.genfromtxt ('../EMG_data/ife_clench.csv', delimiter=\",\")),axis=0)\n",
    "clench_data = np.zeros( (2, int(clench_data_raw.shape[0]/2), 1000 ) )\n",
    "\n",
    "for i in range(0, clench_data_raw.shape[0]):\n",
    "    clench_data[i%2][int((i-i%2)/2)] = clench_data_raw[i][0:1000]\n",
    "\n",
    "clench_data = clench_data.reshape(clench_data.shape[1],clench_data.shape[0], 1000)\n",
    "# print(clench_data.shape)\n",
    "# ---------------------------------------------------------------------------------#\n",
    "wrist_in_data_raw = np.concatenate((np.genfromtxt ('../EMG_data/ife_wrist_in.csv', delimiter=\",\"),np.genfromtxt ('../EMG_data/ife_wrist_in.csv', delimiter=\",\")),axis=0)\n",
    "wrist_in_data = np.zeros( (2, int(wrist_in_data_raw.shape[0]/2), 1000 ) )\n",
    "\n",
    "for i in range(0, wrist_in_data_raw.shape[0]):\n",
    "    wrist_in_data[i%2][int((i-i%2)/2)] = wrist_in_data_raw[i][0:1000]\n",
    "\n",
    "wrist_in_data = wrist_in_data.reshape(wrist_in_data.shape[1],wrist_in_data.shape[0], 1000)\n",
    "# print(wrist_in_data.shape)\n",
    "# ---------------------------------------------------------------------------------#\n",
    "wrist_out_data_raw = np.concatenate((np.genfromtxt ('../EMG_data/ife_wrist_out.csv', delimiter=\",\")\n",
    "wrist_out_data = np.zeros( (2, int(wrist_out_data_raw.shape[0]/2), 1000 ) )\n",
    "\n",
    "for i in range(0, wrist_in_data_raw.shape[0]):\n",
    "    wrist_out_data[i%2][int((i-i%2)/2)] = wrist_out_data_raw[i][0:1000]\n",
    "\n",
    "wrist_out_data = wrist_out_data.reshape(wrist_out_data.shape[1],wrist_out_data.shape[0], 1000)\n",
    "# print(wrist_out_data.shape)\n",
    "\n",
    "#-------------------------------FORMAT--DATA--FOR-TRAINING-------------------------------------#\n",
    "\n",
    "X_data_raw = np.concatenate((wrist_none_data, wrist_in_data, wrist_out_data, clench_data), axis=0)\n",
    "y_data_raw = np.concatenate( ( np.full((wrist_none_data.shape[0]), 0), np.full((wrist_in_data.shape[0]), 1), np.full((wrist_out_data.shape[0]), 2), np.full((clench_data.shape[0]), 3)), axis=0)\n",
    "\n",
    "print('Training data shape:', X_data_raw.shape)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data_raw, y_data_raw, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 1, 2, 1000)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 2, 1024)        9217024   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 1, 2, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 1, 1, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1, 1, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 14,008,452\n",
      "Trainable params: 14,005,380\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitting...\n",
      "Train Data Shape: (178, 1, 2, 1000)\n",
      "Train Labels Shape: (178,)\n",
      "Train on 178 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "178/178 [==============================] - 6s 35ms/step - loss: 1.8792 - acc: 0.4607 - val_loss: 1.4902 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 1s 8ms/step - loss: 1.6865 - acc: 0.5337 - val_loss: 1.1482 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 1s 8ms/step - loss: 1.4335 - acc: 0.5899 - val_loss: 0.8887 - val_acc: 0.6889\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 1s 8ms/step - loss: 1.1675 - acc: 0.6348 - val_loss: 0.9328 - val_acc: 0.6667\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 1s 8ms/step - loss: 1.2124 - acc: 0.5899 - val_loss: 1.4741 - val_acc: 0.6667\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 1s 7ms/step - loss: 1.3146 - acc: 0.5899 - val_loss: 1.7490 - val_acc: 0.6000\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.2605 - acc: 0.5955 - val_loss: 1.4155 - val_acc: 0.7333\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.3057 - acc: 0.5787 - val_loss: 1.1477 - val_acc: 0.7556\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9385 - acc: 0.6966 - val_loss: 1.4899 - val_acc: 0.6222\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9948 - acc: 0.6685 - val_loss: 1.3588 - val_acc: 0.7333\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 1.0712 - acc: 0.6573 - val_loss: 1.5258 - val_acc: 0.7111\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7849 - acc: 0.7022 - val_loss: 1.3760 - val_acc: 0.7111\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8916 - acc: 0.7191 - val_loss: 1.2339 - val_acc: 0.6889\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8279 - acc: 0.7191 - val_loss: 1.6017 - val_acc: 0.7111\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8328 - acc: 0.7247 - val_loss: 1.7917 - val_acc: 0.6667\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7801 - acc: 0.7191 - val_loss: 1.4838 - val_acc: 0.7778\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9245 - acc: 0.7303 - val_loss: 1.4327 - val_acc: 0.6889\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9143 - acc: 0.7079 - val_loss: 1.5382 - val_acc: 0.7556\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8589 - acc: 0.7472 - val_loss: 1.6842 - val_acc: 0.6667\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7165 - acc: 0.7416 - val_loss: 1.9453 - val_acc: 0.6000\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7733 - acc: 0.7697 - val_loss: 1.4986 - val_acc: 0.7333\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7955 - acc: 0.7528 - val_loss: 1.3043 - val_acc: 0.7778\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7138 - acc: 0.7921 - val_loss: 1.6822 - val_acc: 0.6667\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9010 - acc: 0.7022 - val_loss: 1.2777 - val_acc: 0.6000\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8582 - acc: 0.7303 - val_loss: 1.2690 - val_acc: 0.6667\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7718 - acc: 0.7360 - val_loss: 1.3885 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6892 - acc: 0.7753 - val_loss: 1.5173 - val_acc: 0.7111\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8535 - acc: 0.7135 - val_loss: 1.3228 - val_acc: 0.7111\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8933 - acc: 0.7303 - val_loss: 1.2610 - val_acc: 0.7778\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8467 - acc: 0.7697 - val_loss: 1.0732 - val_acc: 0.7111\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8916 - acc: 0.6854 - val_loss: 2.4335 - val_acc: 0.6444\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7626 - acc: 0.7865 - val_loss: 1.2800 - val_acc: 0.7111\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8131 - acc: 0.7640 - val_loss: 0.9600 - val_acc: 0.8444\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7789 - acc: 0.7360 - val_loss: 1.2924 - val_acc: 0.7778\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7694 - acc: 0.7753 - val_loss: 1.4418 - val_acc: 0.7556\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7029 - acc: 0.7528 - val_loss: 1.3598 - val_acc: 0.8889\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8617 - acc: 0.7528 - val_loss: 1.0310 - val_acc: 0.6444\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6951 - acc: 0.7865 - val_loss: 1.0850 - val_acc: 0.8222\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7873 - acc: 0.7022 - val_loss: 1.5855 - val_acc: 0.7778\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9045 - acc: 0.6910 - val_loss: 1.3393 - val_acc: 0.7111\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.8450 - acc: 0.7135 - val_loss: 1.4492 - val_acc: 0.7778\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7566 - acc: 0.7472 - val_loss: 1.9365 - val_acc: 0.6889\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7882 - acc: 0.7528 - val_loss: 1.5587 - val_acc: 0.7111\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7352 - acc: 0.7528 - val_loss: 1.5272 - val_acc: 0.6667\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7625 - acc: 0.7640 - val_loss: 1.6611 - val_acc: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.5690 - acc: 0.8315 - val_loss: 1.6452 - val_acc: 0.7111\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7177 - acc: 0.7865 - val_loss: 1.6127 - val_acc: 0.7333\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6177 - acc: 0.8371 - val_loss: 1.6017 - val_acc: 0.7556\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.5417 - acc: 0.8034 - val_loss: 1.4491 - val_acc: 0.7778\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9083 - acc: 0.7809 - val_loss: 1.5876 - val_acc: 0.7556\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.6908 - acc: 0.7865 - val_loss: 1.6365 - val_acc: 0.6889\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.7787 - acc: 0.7472 - val_loss: 1.6317 - val_acc: 0.7333\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.9393 - acc: 0.6854 - val_loss: 1.7121 - val_acc: 0.7333\n",
      "Model fitting complete\n",
      "45/45 [==============================] - 0s 3ms/step\n",
      "Test accuracy: 0.733333334657881\n"
     ]
    }
   ],
   "source": [
    "g8_model = G8Classifier(X_data_raw, y_data_raw, (1,X_data_raw.shape[1], X_data_raw.shape[2]), epochs=100)\n",
    "g8_model.build_model()\n",
    "g8_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
